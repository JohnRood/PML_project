---
title: "Homebrew_MLE_or_Something"
author: "John Rood"
date: "Sunday, October 25, 2015"
output: html_document
---

# Summary.

An easy way to get the problems all correct was implemented.  In response to comments in the forums, a slightly less easy way was implemented, again getting all the problems correct.  A serious attempt was made to somehow derive these methods from R implementations of General Linear Model functionality.  However, perhaps surprisingly, this did not succeed.  A result of only 8 correct out of 20 was all that could be achieved even with a considerable time investment.  This led to the idea of constructing a scheme to cross validate the first two ways of solving the problems (particularly the second way).  We use a minimalist version of leave-one-out cross-validation.  The results of doing this hint at (very) high accuracy.

# Discussion.

Right.  [sarcasm]

This has been a learning experience.  It is likely there will be further investigation.  However, at the present moment time does not allow detailed explication of what has been learned.

Hopefully the comments in the code explain things satisfactorily.

Question:  Is the present method some kind of global Maximum Likelihood Estimation?

# Appendix.  R code.

Initialize.

```{r}
options( warn = -1 )  ## not good if warnings are not suppressed in this script
pml_ts <- read.csv( "C:/Coursera/Practical_Machine_Learning/work/pml-testing.csv" )
pml_tr <- read.csv( "C:/Coursera/Practical_Machine_Learning/work/pml-training.csv" )
# The present method is based on calculating the sum of absolute differences (SAD).
# So we isolate the floating and integer columns of the data for our use.
bool_numeric_ch_ts <- ( sapply( pml_ts, class )) == "numeric"
bool_integer_ch_ts <- ( sapply( pml_ts, class )) == "integer"
bool_number_ch_ts <- bool_numeric_ch_ts | bool_integer_ch_ts
# Make data with shorter rows--only what we need to use.
sml_ts <- pml_ts[ bool_numeric_ch_ts ]
sml_tr <- pml_tr[ bool_numeric_ch_ts ]
```

How to solve the 20 problems.  Here is the example of the 17th one.

```{r}
## Note:  19622 is the number of observations in the training dataset
good <- rep( 19622, 0 )
# Minimize the Sum of Absolute Differences.  cf Manhattan distance
for (i in 1:19622) { good[i] <- sum(abs(sml_tr[i,] - sml_ts[17,])) }
good2 <- min( good )
good3 <- which.min( good )
ans <- pml_tr[good3,160]
ans
```

Here are the answers.  Presumably these are well known by this point in the project.

```{r}
#ans2 <- rep( "A", 20 )
#filename <- rep( "", 20 )
#for (i in 1:20) {filename[i] <- paste0("C:/Coursera/Practical_Machine_learning/work/10_9/problem_id_", i, ".txt")}
#for (i in 1:20) {ans2[i] <- read.table(filename[i])}
#ans2 <- unlist( ans2 )
#ans2
#   B A B A A E D B A A B C B A E E A B B B
```

How to do leave-one-out cross-validation the hard way (one entry at a time, in this case the randomly generated fifth element to delete).

```{r}
## Note:  19622 is the number of observations in the training dataset
good <- rep( 19621, 0 )
# Create a thousand randomly generated integers within the range of our index.
rng <- sample( 1:19622, 1000 )
seq_1_19622 <- seq( 1:19622 )
# Remove the target observation from our training set.
s_not5 <- seq_1_19622[ -rng[5] ]
sml_tr_not5 <- sml_tr[ s_not5, ]
# Minimize the Sum of Absolute Differences.
for (i in 1:19621) { good[i] <- sum(abs(sml_tr_not5[i,] - sml_tr[rng[5],])) }
good2 <- min( good )
good3 <- which.min( good )
# The following line compares the predicted and actual classe variables.
pml_tr[rng[5],160] == pml_tr[good3,160]
pml_tr[rng[5],160]
```

All of the first five values match.

Or, doing a batch of 20 at once.

```{r}
good5 <- rep( FALSE, 20 )
#The following code takes too long to execute for reasonable processing by Knitr.
#for (j in 1:20) {s_not <- seq_1_19622[ -rng[5+j] ]
#                 sml_tr_not <- sml_tr[ s_not, ]
#                 for (i in 1:19621) { good[i] <- sum(abs(sml_tr_not[i,] - sml_tr[rng[5+j],])) }
#                 good2 <- min( good )
#                 good3 <- which.min( good )
#                 good5[j] <- pml_tr[rng[5+j],160] == pml_tr[good3,160]}
#good5
```

The return value here is:

[1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE

[20] TRUE

At this point it is known that this cross-validation gives correct results on 25 (random) cases.
Specifically we have 25 values of TRUE for the good5's, if you will.

So a crude measure of in sample Accuracy here (on my interpretation) is at least 96%

In fact, with the small number of calculations done here, there have been no errors either in sample or out-of-sample.